\documentclass{article}
\usepackage[margin=1.4in,footskip=0.25in]{geometry}
\setlength\parindent{0pt} % no indents
\usepackage{listings}
\usepackage{color}
\usepackage{longtable}
\usepackage{textcomp}
\definecolor{listinggray}{gray}{0.9}
\definecolor{lbcolor}{rgb}{0.9,0.9,0.9}
 \usepackage{graphicx}
 \usepackage{setspace}
 \usepackage{parskip}
\lstset{
backgroundcolor=\color{lbcolor},
tabsize=3,
rulecolor=\color{white},
language=python,
basicstyle=\scriptsize,
upquote=true,
aboveskip={0.75\baselineskip},
columns=fixed,
showstringspaces=false,
extendedchars=true,
breaklines=true,
prebreak=,
breakindent=0.5em,
frame=single,
showtabs=false,
showspaces=false,
showstringspaces=false,
identifierstyle=\ttfamily,
keywordstyle=\color[rgb]{0,0,1},
commentstyle=\color[rgb]{0.133,0.545,0.133},
stringstyle=\color[rgb]{0.627,0.126,0.941},
}
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.3}
\hypersetup{colorlinks,breaklinks,
            linkcolor=blue,urlcolor=blue,
            anchorcolor= blue,citecolor= blue,citebordercolor=Violet, filebordercolor=Red,linkbordercolor=Blue}
            
\newcommand{\figurewrap}[2]{\begin{figure}[h!]
\centering
\includegraphics[width=#2\textwidth]{#1}
\end{figure}}

\newcommand{\optEntry}[4]{\textbf{#1} (type=#2, default=#3) #4\hspace{0.5em}\\}
\newcommand{\ag}{audioguide1.1 }
\newcommand{\Ag}{Audioguide1.1 }

\usepackage[table]{xcolor}
\begin{document}
\setlength{\parskip}{10pt}
\begin{spacing}{1.2}
\begin{center}
\includegraphics[width=0.75\textwidth]{image0.png}

By Ben Hackbarth, Norbert Schnell, Philippe Esling, Diemo Schwarz. \\
Copyright Ben Hackbarth, 2011-2013.
\end{center}

\tableofcontents


\section{Installation}
For the moment \ag only works on OS X.  More recent versions of OS X  (after 10.5) come with python2.7 that automatically has numpy installed.  This distribution of \ag comes with a precompiled version of pysdif for 64-bit python and, on more current machines, should run out of the box.  Here is a complete list of the resources that \ag requires on your computer:
\begin{description}
\item[ircamdescriptors] \Ag uses IRCAM's \href{http://www.ircam.fr/1041.html?&L=1}{descriptor analysis binary}.  It is included this distribution.
\item[pysdif] To compile install download the \href{http://sourceforge.net/projects/sdif/files/sdif/}{sdif library} and configure, make and install.  Then download my patched version of the \href{http://www.benhackbarth.com/\ag/pysdif-0.1.4-patch.zip}{pysdif module}.  `cd' into the directory when unzipped and run: `python2.7 setup.py install'.  You're now setup to use pysdif in python2.7.
\item[numpy] Most python2.7 installations come with numpy, a numerical computation module.  Upgrading to the latest python2.7 should get you there.  If you don't have it, you can download the source code or a binary installer \href{http://www.scipy.org/install.html}{here}.
\item[csound] Needed only if you would like \ag to automatically render concatenations (which you probably do).  Download an installer from \href{http://www.csounds.com/downloads}{here}.

\end{description}

  


\section{Quick Start}
Using \ag comes down to interacting with python scripts in the \ag folder.  For soundfile concatenation, one script does segmentation of corpus soundfiles.  A second script performs concatenation based on a variety of variables found in a options file.  While you do not need to know how to write Python code in order to use \ag, it is not a bad idea to know some of Python's basic syntax.

The reason that segmentation and concatenation are separated into discrete steps that I find is useful to fine-tune the segmentation of corpus sounds \emph{before} using them in a concatenation.  Soundfile segmentation is a difficult technical problem and should remain conceptually and aesthetically open-ended.  I have yet to find an algorithm that does not require adjustments based on the nature of the sound in question and the intention of the user as to what a segment should be.


\subsection{Segmenting Corpus Soundfiles}
\emph{Note}: If you only want to use folders of sounds that have been pre-segmented into individual files, you can skip\footnote{But make sure tell \ag not to search for segmentation textfiles by setting the corpus attribute wholeFIle=True.  See the Manipulating How Directories Are Read subsection of the CORPUS options section for more info.} the \emph{Segmenting Corpus Soundfiles} section and proceed to the concatenation section.

The script you use to segment your corpus files with a script called `agSegmentSf.py'.  The output of agSegmentSf.py is a textfile which denotes the start and stop times of autonomous sound segments in a continuous audiofile.  Once you find a segmentation that you're happy with, you don't need to keep running this script.
Whats more, you do not \emph{need} to use `agSegmentSf.py' if you do not want to -- instead you could:
\begin{enumerate}
\item use whole soundfiles as segments
\item create segmentation files by hand
\item create segmentation files with other software as long the textfile is written in the same format as \ag's.
\end{enumerate}

To segment a corpus file, `cd' into the \ag folder and run the following command:

\begin{lstlisting}[language=python]
$ > python2.7 agSegmentSf.py examples/lachenmann.aiff
\end{lstlisting}

\ag will think for a second, and then output the following data detailing the segmentation of this audiofile:

\begin{lstlisting}[language=python]
------------------- \ag SEGMENT SOUNDFILE -------------------


	Found 86 segments in /Users/ben/Desktop/\ag-1.1.0/examples/lachenmann.aiff
	Wrote target label file /Users/ben/Desktop/\ag-1.1.0/examples/lachenmann.aiff.txt
\end{lstlisting}

As a result of running this python script, \ag wrote a textfile called examples/lachenmann.aiff.txt.  In it are 86 segments obtained using a triggering threshold of -40 dB, a rise ratio of 1.3 and a offset dB value of -54 (you can read more about how to alter these values and their effect in the subsequent section).

\subsection{Concatenating}
Next you call the concatenate script agConcatenate.py with an \ag options file as the first (and only) argument.  

To run one of the examples in the examples directory, run the following command inside the \ag directory:
\begin{lstlisting}[language=python]
python2.7 agConcatenate.py examples/01-simplest.py
\end{lstlisting}

..which will use the options contained in `examples/01-simplest.py' to parameterize the concatenative algorithm.  In this file you specify the target sound, the corpus sounds, and perhaps lots of other options that parameterize the concatenative process.  The `agConcatenate.py' script will perform the following operations:
\begin{enumerate}
\item Run an ircamdescriptor analysis of the soundfile in the \ref{target} TARGET variable\footnote{An SDIF analysis is only done once -- subsequent usages of a soundfile simply read SDIF data from disk.  Analysis files are stored in a directory called `\ag/data\_json/' in the \ag folder.  This directory can become quite large since these SDIF files are quite large in size.  Removing this folder will cause all SDIF files to be recomputed.}.  
\item Segment the target sound according to your options file.  An Audacity-style label file is created in a file called `output/tgtLabels.txt' in the output directory.
\item Run an ircamdescriptor analysis of the soundfiles in the CORPUS variable (only the first time each of these files are used).
\item (If you've specified them) Remove corpus segment according to descriptor limitations (Nothing above a certain pitch, nothing below a certain dynamic, etc.).
\item Normalise target and corpus descriptor data according to your options file.
\item Go through each target segment one by one.  Select corpus segment(s) to match each target segment according to the descriptors and search passes in the SEARCH variable of your options file.  Control over the layering and superimposition of corpus sounds is specified in the SUPERIMPOSE variable.
\item Write selected segments to a sound score called `output/output.csd' in the output directory.  There are many other types of outputs which you can read about in the output file subsection \ref{outputfiles} in the last part of this document.
\item If you have csound, `output/output.csd' is rendered with csound to create an audiofile called `output/output.aiff'.
\item If you have csound, automatic playback of `output/output.aiff' at the command line.
\end{enumerate}


\section{Corpus Segmentation}
`agSegmentSf.py' uses a segmentation labeling format identical to that of the soundfile editor Audacity.  So, to examine your segments, open lachenmann.aiff in Audacity, then import labels and select `examples/lachenmann.aiff.txt'.

\figurewrap{image1.png}{1}

Segmentation textfiles document one segment per line. here is an example line: `1.50 2.13 onset -12.9 offset rise 1.33'.

Everything after startSec and endSec is not required by \ag, but give you information about the segmentation logic.  These fields correspond to: startSec endSec onset thresholdValue offset offsetMethod methodValue.

.. and indicate ..

\subsection{Onset Detection}
thresholdValue: the value of the threshold which triggered this segment's onset. it is in negative dB where -100 dB is very soft and -6 dB is very loud. you can change the threshold level that triggers onsets by passing the agSegmentSf.py script a `-t' flag:
\begin{lstlisting}[language=python]
./agSegmentSf.py -t -30 soundfilename.wav
\end{lstlisting}
...sets the threshold to -30. it will produce less onsets then -40 (the default).

\subsection{Offset Detection}
\ag's soundfile segmentation uses two methods for creating an offset (an offset means to end a currently active sound segment).  
The first method is simple -- if the amplitude of a segment drops below a certain dB threshold, called `drop' and can be changed from its default value using the `-d' flag.

\begin{lstlisting}[language=python]
python2.7 agSegmentSf.py -d 4 soundfilename.wav
\end{lstlisting}

... which changes the drop dB value to 4 dB above the minimum amplitude found in the entire soundfile.

The second method is more complicated: if the amplitude of the sound is louder that the previous value and the ratio of the current value over the previous value is above the `rise ratio'.  This is a very useful construct: imagine that you are in a current sound segment, but the soundfile suddenly gets much louder, and you'd like to end the current segment so that you may start a new one which reflects this change.  You can override the default rise ratio (1.1) using the `-r' flag:

\begin{lstlisting}[language=python]
python2.7 agSegmentSf.py -r 4 soundfilename.wav
\end{lstlisting}

...a value of 1.1 will be quite sensitive to changes in amplitude.  A value of 4 will be less sensitive - a larger crescendo is needed to turn off a currently active segment.

Note that to segment a whole directory of soundfiles, you may use wildcard characters in the bash shell, as in:
\begin{lstlisting}[language=python]
python2.7 agSegmentSf.py mydir/*.aiff # create a segmentation file for each aiff file located in mydir/
\end{lstlisting}


\section{The Concatenate Options File}
The options file used by the concatenate script if a python file that defines a bunch of variables.  Most variables are changed with simple assignments using the `=' symbol.  For instance, to change the path of the csound output sound file, write the following in your options.py file:
\begin{lstlisting}
CSOUND_RENDER_FILEPATH = '/path/to/the/file/i/want.aiff' # sets the path of the csound output aiff file
LOG_FILEPATH = None # None tells \ag not to make a log output file.
\end{lstlisting}


However, there are five objects that are written into the options file as well -- `tsf', `csf', `spass', `d', `si'.  These objects take required parameters and also take keyword arguments.  The following sections describe the object-style variables.

\subsection{The TARGET Variable}\label{target}
The TARGET variable is written as a `tsf' object which requires the path to a soundfile and also takes the following optional keyword arguments:

\begin{lstlisting}[language=python]
tsf('path', start=0, end=file-length, thresh=-40, rise=1.5, scaleDb=0, minSegLen=0.05, maxSegLen=1000, midiPitchMethod='composite', stretch=1)
\end{lstlisting}

\begin{description}
\item[start] The time in seconds to start reading the target soundfile.
\item[end] The time in seconds to stop reading the target soundfile.  
\item[scaleDb] Applies an amplitude change to the target sound. by default, it is 0, yielding no change. -6 = twice as soft.  The target's amplitude will usually affect concatenation: the louder the target, the more corpus sounds can be composted to approximate it energy.
\item[thresh] Set the threshold for segmentation: a value in negative dB.  The lower the value the soft the target's amplitude can be in order to trigger a selection from the corpus.  So, -12 yields fewer corpus selections that -24.
\item[rise] undocumented !  sorry.
\item[minSegLen] The minimum duration in seconds of a target segment.
\item[maxSegLen] The maximum duration in seconds of a target segment.
\item[midiPitchMethod] undocumented !  sorry.
\item[stretch] undocumented !  sorry.
\end{description}

\begin{lstlisting}[language=python]
TARGET = tsf('cage.aiff') # uses the whole soundfile at its given amplitude
TARGET = tsf('cage.aiff', start=5, end=7, scaleDb=6) # only use seconds 5-7 of cage.aiff at double the amplitude.
\end{lstlisting}


\subsection{The CORPUS Variable}
The CORPUS variable is defined as a list of `csf' objects which require a path to a soundfile OR a directory.  File paths and/or directory paths may be full paths or relative paths to the location of the options file you're using.  A `csf' object takes the following optional keyword arguments:

\begin{lstlisting}[language=python]
csf('pathToFileOrDirectoryOfFiles', allowRepetition=True, concatFileName=None,  end=None,  envelopeSlope=1,  excludeStr=None,  excludeTimes=[], hasParams=False, includeStr=None,  includeTimes=[],  limit={},  limitDur=None,  midiPitchMethod='composite',  offsetLen='30\%',  onsetLen=0.01,  recursive=True,  restrictInTime=0,  restrictOverlaps=None,  restrictRepetition=0.1,  scaleDb=0.0,  scaleDistance=1,  postSelectAmpBool=False, postSelectAmpMin=-12, postSelectAmpMax=+12, postSelectAmpMethod='power-mean-seg', segmentationExtension='.txt',  segmentationFile=None,  start=None,  superimposeRule=None,  transMethod=None,  transQuantize=0,  wholeFile=False, MWinstrName=None,  MWtext=None, MWnotehead='.')
\end{lstlisting}


The simplest way to include a soundfile in your corpus is to use its path as the first argument of the `csf' object:
\begin{lstlisting}
CORPUS = [csf("lachenmann.aiff")] # will search for a segmentation file called lachenmann.aiff.txt and add all of its segments to the corpus
\end{lstlisting}

The simplest way to include a directory of soundfiles in your corpus is to use its path as the first argument of the `csf' object:
\begin{lstlisting}
CORPUS = [csf("lachenmann.aiff"), csf('piano')] # will use segments from lachenmann.aiff as well as all sounds in the directory called piano
\end{lstlisting}

\noindent However, as you can see above, each `csf' object has \emph{a lot} of optional arguments to give you better control over what segments are used, how directories are read and how segments are treated during concatenation.  

\emph{Note: Each of these keyword arguments only apply to the csf object within which they are written.  If you'd like to specify these parameters for the entire corpus, see section 4.2.5: Specifying CORPUS entry attributes globally.}

\subsubsection{Manipulating which segments are added to the corpus}
\begin{description}
\item[start] Any segments which start before this time will be ignored.
\item[end] Any segments which start after this time will be ignored.
\end{description}

\begin{lstlisting}[language=python]
csf('lachenmann.aiff', start=20) # only use segments who start later than 20s.
csf('lachenmann.aiff', start=20, end=50) # only use segments who start between 20-50s.
\end{lstlisting}

\begin{description}
\item[includeTimes] A list of two-number lists which specify regions of segments to include from this file's list of segment times.  See example below.
\item[excludeTimes] Same as includeTimes but excludes segments in the identified regions.
\end{description}

\begin{lstlisting}
csf('lachenmann.aiff', includeTimes=[(1, 4), (10, 12)]) # only use segments falling between 1-4 seconds and 10-12 seconds.
csf('lachenmann.aiff', excludeTimes=[(30, 55)]) # use all segments except those falling between 30-55s.
\end{lstlisting}

\begin{description}
\item[limit] A list of equation-like strings where segmented descriptor names are used to include/exclude segments from this file / directory.
\end{description}
\begin{lstlisting}
csf('lachenmann.aiff', limit['centroid-seg >= 1000']) # segments whose centroid-seg is equal to or above 1000.

csf('lachenmann.aiff', limit['centroid-seg < 50%']) # only use 50% of segments with the lowest centroid-seg.

csf('lachenmann.aiff', limit['power-seg < 50%', 'power-seg > 10%']) # only use segments whose power-seg falls between 10%-50% of the total range of power-seg's in this file/directory.
\end{lstlisting}



\subsubsection{Manipulating How Directories Are Read}
The following keyword arguments are useful when dealing with directories of files.
\begin{description}
\item[wholeFile] (False): if True \ag will use this soundfile as one single segment.  If False, \ag will search for a segmnetation file made with agSegmentSf.py.

\item[recursive] (True): if True \ag will include sounds in all subfolders of a given directory.
\end{description}

\begin{lstlisting}
csf('sliced/my-directory', wholeFile=True) # will not search for a segmentation txt file, but use whole soundfiles as single segments.

csf('/Users/ben/gravillons', recursive=False) # will only use soundfiles in the named folder, ignoring its subdirectories.
\end{lstlisting}

\begin{description}
\item[includeStr] (None): A string which is matched against the filename (not full path) of each soundfile in a given directory.  If part of the soundfile name matches this string, it is included.  If not it is excluded.  This is case sensitive.  See example below.

\item[excludeStr] (None): Opposite of includeStr.
\end{description}

\begin{lstlisting}
# includeStr/excludeStr have lots of uses.  One to highlight here: working with sample databases which are normalized.  Rather than having each corpus segment be at 0dbs, we apply a scaleDb value based on the presence of a `dynamic' written into the filename.
csf('Vienna-harpNotes/', includeStr=['_f_', '_ff_'], scaleDb=-6),
csf('Vienna-harpNotes/', includeStr='_mf_', scaleDb=-18),
csf('Vienna-harpNotes/', includeStr='_p_', scaleDb=-30),
# this will use all sounds from this folder which match one of the three dynamics.
\end{lstlisting}





\subsubsection{Manipulating How Segments Will Be Concatenated}
\begin{description}
\item[scaleDb] applies an amplitude change to each segment of this collection. by default, it is 0, yielding no change. -6 = twice as soft.  Note that amplitude scaling affects both the concatenative algorithm and the csound rendering.  

\item[onsetLen] if onsetLen is a float or integer, it is the fade-in time in seconds.  If it is a string formed as '10\%', it is interpreted as a percent of each segment's duration.  So, onsetLen=0.1 yields a 100 ms. attack envelope while onsetLen='50\%' yields a fade in over 50\% of the segment's duration.

\item[offsetLen] Same as onsetLen, but for the envelope fade out.

\end{description}
\begin{lstlisting}
csf('lachenmann.aiff', onsetLen=0.1, offsetLen='50%') # will use a segmentation file called marmotTent.txt, not the default lachenmann.aiff.txt.
\end{lstlisting}
\begin{description}

\item[transMethod] A string indicating how to transpose segments chosen from this corpus entry.

\item[transQuantize] Quantization interval for transposition of corpus sounds.  1 will quantize to semitones, 0.5 to quarter tones, 2 to whole tones, etc.

\end{description}
\begin{lstlisting}
csf('piano/', transMethod='f0') # transpose corpus segments to match the target's f0.
csf('piano/', transMethod='f0-chroma', transQuantize=0.5) # transpose corpus segments to match the target's f0 mod 12.  Then quantize each resulting pitch to the newest quarter of tone.
\end{lstlisting}
\begin{description}

\item[allowRepetition] If False, any of the segments from this corpus entry may only be picked one time.  If True there is no restriction.

\item[restrictRepetition] A delay time in seconds where, once chosen, a segment from this corpus entry is invalid to be picked again.  The default is 0.1, which the same corpus segment from being selected in quick succession.

\end{description}
\begin{lstlisting}
csf('piano/', allowRepetition=False) # each individual segment found in this directory of files may only be deleted one time during concatenation.
csf('piano/', restrictRepetition=2.5) # Each segment is invalid to be picked if it has already been selected in the last 2.5 seconds.
\end{lstlisting}
\begin{description}


\item[restrictOverlaps] An integer specifying how many overlapping samples from this collection may be chosen by the concatenative algorithm at any given moment.  So, restrictOverlaps=2 only permits 2 overlapping voices at a time.

\item[restrictInTime] a time in seconds specifying how often a sample from this entry may be selected. -- for example restrictInTime=0.5 would permit segments from this collection to be select a maximum of once every 0.5 seconds.

	%\item scaleDistance (1): Adjust the distance when executing a multidimensional search using these segments.  scaleDistance=2 will make these sounds twice as `far', and thus less likely to be selected by the search algorithm.  scaleDistance=0.25 makes _more_ likely to be picked.

\item[superimposeRule]  This one is a little crazy.  Basically, you can specify when this corpus's segments can be chosen based on the number of simultanously selected samples.  You do this by writing a little equation as a 2-item list.  superimposeRule=('==', 0) says that this set of corpus segments may only be chosen is this is the first selection for this target segment (sim selection `0').  superimposeRule=('>', 2) say this corpus's segments are only valid to by picked if there are already more than 2 selections for this target segment.  I know, right?
\end{description}


\subsubsection{Miscellaneous}
\begin{description}
\item[segmentationFile] Manually specify the segmentation text file. By default, \ag automatically looks for a file with the same name as the soundfile plus the extension '.txt'. You may specify a string, or a list of strings to include multiply segmentation files which all use the same soundfile.

\item[segmentationExtension] Manually specify the segmentation text file extension.
\end{description}

\begin{lstlisting}
csf('lachenmann.aiff', segmentationFile='marmotTent.txt') # will use a segmentation file called marmotTent.txt, not the default lachenmann.aiff.txt.

csf('lachenmann.aiff', segmentationExtension='-gran.txt') # will use a segmentation file called lachenmann.aiff-gran.txt, not the default lachenmann.aiff.txt.
\end{lstlisting}


\subsubsection{Specifying CORPUS entry attributes globally}
Corpus entry attributes may be specified globally using the variable CORPUS\_GLOBAL\_ATTRIBUTES.  Note that they are specified in dictionary format rather than keyword format.

\begin{lstlisting}
CORPUS = [csf('lachenmann.aiff', scaleDb=-6), csf('piano/', scaleDb=-6, wholeFile=True)]

# is equivalent to 

CORPUS = [csf('lachenmann.aiff'), csf('piano/', wholeFile=True)]
CORPUS_GLOBAL_ATTRIBUTES = {'scaleDb': -6}
\end{lstlisting}


\subsection{The SEARCH Variable}
the SEARCH variable specifies how \ag pick corpus segments to match target segments.  The idea here is make a \emph{very} flexible searching structure where the user can create multiple search passes on different criteria.


\subsection{SEARCH and spass objects}

The SEARCH variable is written as a list of `spass' objects.  
\begin{lstlisting}
spass(result_type, descriptor1... descriptorN, percent=None, minratio=None, maxratio=None)
\end{lstlisting}

Here is the most simple case:
\begin{lstlisting}
SEARCH = [spass('closest', d('centroid'))] # will search all corpus segments and select the one with the `closest' centroid to the target segment.
\end{lstlisting}

Note that the first argument is the type of search performed -- in this case, selecting the closest sample.  Following the arguments are a list of descriptor objects which specify which descriptors to use.  Finally there are some keyword parameters that we will touch on later.

\begin{lstlisting}
SEARCH = [spass('closest', d('centroid'), d('effDur-seg'))] # will search all corpus segments and select the one with the `closest' centroid and effective duration compared to the target segment.
\end{lstlisting}

Ok, great.  As you can probably imagine, the first argument, `closest', tells \ag to pick the closest sound.  But, there are also other possibilities:

\begin{lstlisting}
SEARCH = [spass('farthest', d('centroid'))] # return the worst matching segment.

SEARCH = [spass('closest_percent', d('centroid'), percent=20)] # return the top 20 percent best matches.

SEARCH = [spass('farthest_percent', d('centroid'), percent=20)] # return the worst 20 percent of matches.
\end{lstlisting}

If you use `closest\_percent' or `farthest\_percent' as the one and only spass object in the SEARCH variable, \ag will select a corpus segment randomly among the final candidates.  However, you can also chain spass objects together, essentially constructing a hierarchical search algorithm.  So, for example, take the following SEARCH variable with two separate phases:

\begin{lstlisting}
SEARCH = [
spass('closest_percent', d('effDur-seg'), percent=20), # take the best 20% of matches from the corpus
spass('closest', d('mfccs')), # now find the best matching segment from the 20 percent that remains.
] 
\end{lstlisting}

I use the above example a lot when using \ag.  It first matches effDur-seg, the effective duration of the target measured agains't the effective duration of each corpus segment.  It retains the 20\% closest matches, and throws away the worst 80\%.  Then, with the remaining 20\%, the timbre of the sounds are matched according to mfccs.

\begin{lstlisting}
SEARCH = [spass('ratio_limit', d('centroid-seg'), minratio=0.9, maxratio=1.1)] # reduce the number of samples in the corpus such 
\end{lstlisting}

Remember, the order of the spass objects in the SEARCH variable is very important -- it is essentially the order of operations.

\subsubsection{The D object}
Use the `d' object for specifying a descriptor in the SEARCH variable.

 \begin{lstlisting}[language=python]
d('descriptor name', weight=1, norm=2, normmethod='stddev', distance='euclidean', energy=False)
\end{lstlisting}
 
\begin{description}

\item[weight] How to weight this descriptor in relation to other descriptors.

\begin{lstlisting}
SEARCH= [spass('closest', d('centroid', weight=1), d('noisiness', weight=0.5))] # centroid is twice as important as noisiness.
\end{lstlisting}

\item[norm] A value of 2 normalizes the target and corpus data separately.  A value of 1 normalizes the target and corpus data together.  2 will yield a better rendering of the target's temporal contour.  1 will remain more faithful to concrete descriptor values.  I recommend using 2 by default, only using 1 when dealing with very `descriptive' descriptors like duration or pitch.

\begin{lstlisting}
SEARCH= [spass('closest', d('centroid'), d('effDur-seg', norm=1))]
\end{lstlisting}

\item[normmethod] How to normalize data -- either 'stddev' or 'minmax'.  minmax is more precise, stddev is more forgiving of `outliers.'

\item[distance] Only valid for time-varying descriptors.  How to arithmetically evaluate distance between continuously valued array.  'euclidean' does a simple least squares search.  Other methods include 'pearson', 'buttuck' and 'logjammin'.

\begin{lstlisting}
SEARCH= [spass('closest', d('centroid', distance='pearson'))] # uses a pearson correlation formula for determining distance between the continuously valued centroid of target and corpus segments.
\end{lstlisting}

\item[energy] Only valid for time-varying descriptors.  Weight distance calculations with the corpus segments energy values.  So, softer frames will not penalize distance.
\end{description}

\section{Examples}
\subsection{Example 1}

\lstinputlisting{/Users/ben/Documents/audioguide1.1/examples/01-simplest.py}



\section{The SUPERIMPOSE variable}
Use the `si' object for specifying how corpus segments may be superimposed during concatenation.

 \begin{lstlisting}[language=python]
SUPERIMPOSE = si(minSegment=None, maxSegment=None, minOnset=None, maxOnset=8, minOverlap=None, maxOverlap=None, overlapAmpThresh=-70., searchOrder='power', calcMethod='mixture', peakAlign=False)
\end{lstlisting}
 
\begin{description}

\item[minSegment] The minimum number of corpus segments that must be chosen to match a target segment.
\item[maxSegment] The maximum number of corpus segments that must be chosen to match a target segment.
\item[minOnset] The minimum number of corpus segments that must be chosen to begin at any single moment in time.
\item[maxOnset] The maximum number of corpus segments that must be chosen to begin at any single moment in time.
\item[minOverlap] The minimum number of overlapping corpus segments at any single moment in time.  Note that an `overlap' is determined according to an amplitude threshold -- see overlapAmpThresh.
\item[maxOverlap] The maximum number of overlapping corpus segments at any single moment in time.  Note that an `overlap' is determined according to an amplitude threshold -- see overlapAmpThresh.

\item[overlapAmpThresh] 

\item[searchOrder] (`power' or `time')  The default is `time', which indicated to match corpus segments to target segments in the temporal order of the target (i.e., first searched segment is the first segment in time).  `power' indicates to first sort the target segments from loudest to softest, then search for corpus matches.

%\item[subtractDur] corpusEffDur ||  targetEffDur || corpusDur
%\item[ampDur] corpusEffDur ||  targetEffDur || corpusDur
%\item[overlapDur] corpusEffDur ||  targetEffDur || corpusDur.  Don't go changin me.
%\item[simCalcDur] least || most || corpusEffDur ||  targetEffDur || corpusDur

\item[calcMethod] A string which denotes how to calculate overlapping corpus sounds.  None does nothing -- each corpus selection is unaware of previous selections.  `subtract' subtracts the energy of a selected corpus sound from the target's amplitude so that future selections might be later in time and softer.  `mixture' subtracts the amplitude and then attempts to mix the descriptors of simultaneous sounds together.  Note that some descriptors are not algorithmically mixable, such as f0, zeroCross, and peak descriptors.
\end{description}



\section{Other Options}
\subsection{Descriptor Computation Parameters}
\optEntry{DESCRIPTOR\_FORCE\_ANALYSIS}{bool}{False}{if True forces \ag to remake SDIF analysis, even if previously made.}

\optEntry{DESCRIPTOR\_WIN\_SIZE\_SEC}{float}{0.04643990929708}{the FFT window size of descriptor analysis in seconds.  0.046 seconds = 2048 @ 44.1 kHz}

\optEntry{DESCRIPTOR\_HOP\_SIZE\_SEC}{float}{0.01160997732427}{the FFT window overlaps of descriptor analysis in seconds.  Important, as it effectively sets of temporal resolution of \ag.}

\optEntry{IRCAMDESCRIPTOR\_RESAMPLE\_RATE}{int}{12500}{see ircamdescriptor documentation for details.}

\optEntry{IRCAMDESCRIPTOR\_WINDOW\_TYPE}{string}{blackman}{see ircamdescriptor documentation for details.}

\optEntry{IRCAMDESCRIPTOR\_NUMB\_MFCCS}{int}{13}{sets the number of MFCCs to make.  \emph{Doesn't seem to work} in this release, as 13 is all I can ever seem to get out of the library.}

\optEntry{IRCAMDESCRIPTOR\_F0\_MAX\_ANALYSIS\_FREQ}{float}{5000}{see ircamdescriptor documentation for details.}

\optEntry{IRCAMDESCRIPTOR\_F0\_MIN\_FREQUENCY}{float}{20}{minimum possible f0 frequency.}

\optEntry{IRCAMDESCRIPTOR\_F0\_MAX\_FREQUENCY}{float}{5000}{maximum possible f0 frequency.}

\optEntry{IRCAMDESCRIPTOR\_F0\_QUALITY}{float}{0.1}{see ircamdescriptor documentation for details.}

\optEntry{SUPERVP\_STRETCH\_FLAGS}{string}{-Afft -Np0 -M0.092879802s -oversamp 8 -Whamming -P1 -td\_thresh 1.2 -td\_G 2.5 -td\_band 0,22050 -td\_nument 10 -td\_minoff 0.02s -td\_mina 9.9999997e-06 -td\_minren 0 -td\_evstre 1 -td\_ampfac 1.5 -td\_relax 100 -td\_relaxto 1 -FCombineMul -shape 1 -Vuf -4}{flags used for time stretching target sounds with supervp.  I wouldn't try to change this...}

\optEntry{SUPERVP\_BIN}{string/None}{None}{}

\optEntry{PM2\_BIN}{string/None}{None}{}


\subsection{Concatenation}
\optEntry{RANDOM\_SEED}{int/None}{None}{sets the pseudo-random seed for random unit selection.  By default a value of None will use the system's timestamp.  Setting an integer will create repeatable random results.}

\optEntry{OUTPUT\_GAIN\_DB}{int/None}{None}{adds a uniform gain in dB to all selected corpus units.  Affects the subtractive envelope calculations and descriptor mixtures as well as csound rendering.}

\optEntry{OUTPUT\_TIME\_STRETCH}{float}{1.}{stretch the temporality of selected units.  A value of 2 will stretch all events offsets by a factor of 2.}

\optEntry{OUTPUT\_TIME\_ADD}{float}{0.}{offset the start time of selected events by a value in seconds.}

\subsection{Output Files}\label{outputfiles}
For each of the following *\_FILEPATH variables, a value of None tells the agConcatenate.py NOT to create an output file.  Otherwise a string tells agConcatenate.py to create this output file and also indicates the path of the file to create.  Strings may be absolute paths.  If a relative path is given, \ag will create the file relative to the location o the agConcatenate.py script.

\optEntry{CSOUND\_CSD\_FILEPATH}{string/None}{output/output.csd}{creates an output csd file for rendering the resulting concatenation with csound.}

\optEntry{CSOUND\_RENDER\_FILEPATH}{string/None}{output/output.aiff}{sets the sound output file in the CSOUND\_CSD\_FILEPATH file.  This is the name of csound's output soundfile and will be created at the end of concatenation.}

\optEntry{LOG\_FILEPATH}{string/None}{output/log.txt}{a log file with lots of information from the concatenation algorithm.}

\optEntry{MIDI\_FILEPATH}{string/None}{output/output.mid}{a midi file of the concatenation with pitches chosen according to midiPitchMethod from each corpus entry.}

\optEntry{TARGET\_SEGMENT\_LABELS\_FILEPATH}{string/None}{output/targetlabels.txt}{Audacity-style labels showing how the target sound was segmented.}

\optEntry{SUPERIMPOSITION\_LABEL\_FILEPATH}{string/None}{output/superimpositionlabels.txt}{Audacity-style labels showing the selected corpus sounds and how they overlap.}

\optEntry{LISP\_OUTPUT\_FILEPATH}{string/None}{output/output.lisp.txt}{a textfile containing selected corpus events as a lisp-style list.}

%\optEntry{PARAM\_SCORE\_FILEPATH}{string/None}{output/paramscore.txt}{.}

\optEntry{DICT\_OUTPUT\_FILEPATH}{string/None}{output.json}{a textfile containing selected corpus events in json fotmat.}

\optEntry{TARGET\_DESCRIPTORS\_FILEPATH}{string/None}{targetdescriptors.json}{saves the loaded target descriptors to a json dictionary.}

\optEntry{TARGET\_PLOT\_DESCRIPTORS\_FILEPATH}{string/None}{None}{creates a plot of each target descriptor used in concatenation.  Doesn't work for averaged descriptors (``-seg''), only time varying descriptors.}


\subsection{Printing/Interaction}
\optEntry{ALERT\_ON\_ERROR}{bool}{False}{will attempt to play the system alert sound when exiting with an error.  Pretty irritating, but then again you probably deserve it.}

\optEntry{VERBOSITY}{int}{2}{affects the amount of information \ag prints to the terminal.  A value of 0 yields nothing.  A value of 1 prints a minimal amount of information.  A value of 2 (the default) prints refreshing progress bars to indicate the progress of the algorithms.}

\optEntry{PRINT\_SELECTION\_HISTO}{bool}{False}{if True will print robust information about corpus selection after concatenation.  If false (the default) will add this information to the log file, if used.}

\optEntry{PRINT\_SIM\_SELECTION\_HISTO}{bool}{False}{if True will print robust information about corpus overlapping selection after concatenation.  If false (the default) will add this information to the log file, if used.}



\end{spacing}
\end{document}

 

